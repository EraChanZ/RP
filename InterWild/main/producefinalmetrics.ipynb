{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Using GPU: 0\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import torch\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, osp.join('..', 'main'))\n",
    "sys.path.insert(0, osp.join('..', 'data'))\n",
    "sys.path.insert(0, osp.join('..', 'common'))\n",
    "from config import cfg\n",
    "import argparse\n",
    "\n",
    "cfg.set_args(\"0\", False)\n",
    "cfg.num_thread = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_new_coral import get_model\n",
    "\n",
    "source_ckpt = r\"C:\\Users\\vladi\\RP\\InterWild\\demo\\snapshot_6.pth\"\n",
    "model = get_model(mode='test')\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "ckpt = torch.load(source_ckpt)\n",
    "load_info = model.load_state_dict(ckpt['network'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You are using a MANO model, with only 10 shape coefficients.\n",
      "WARNING: You are using a MANO model, with only 10 shape coefficients.\n",
      "Fix shapedirs bug of MANO\n"
     ]
    }
   ],
   "source": [
    "from train_ssa import CustomHandLandmarksDataset\n",
    "import torchvision.transforms as transforms\n",
    "val_dataset_target_part1 = CustomHandLandmarksDataset(\n",
    "    image_dir=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\IR\",\n",
    "    annotations_path=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\combined_FIX_IR.json\",\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "val_dataset_target_part2 = CustomHandLandmarksDataset(\n",
    "    image_dir=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\IR\",\n",
    "    annotations_path=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\IR\\landmarks.json\",\n",
    "    transform=transforms.ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_source_part1 = CustomHandLandmarksDataset(\n",
    "    image_dir=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\RGB\", \n",
    "    annotations_path=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\combined_FIX_RGB.json\",\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "val_dataset_source_part2 = CustomHandLandmarksDataset(\n",
    "    image_dir=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\RGB\", \n",
    "    annotations_path=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\RGB\\landmarks.json\",\n",
    "    transform=transforms.ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_target_cleaned_part1 = CustomHandLandmarksDataset(\n",
    "    image_dir=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\IR_copy\\allvisible\",\n",
    "    annotations_path=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\combined_FIX_IR.json\",\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "val_dataset_target_cleaned_part2 = CustomHandLandmarksDataset(\n",
    "    image_dir=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\IR_copy\\allvisible\",\n",
    "    annotations_path=r\"C:\\Users\\vladi\\RP\\our_hands_dataset_labeled_previews\\IR\\landmarks.json\",\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (body_backbone): ResNetBackbone(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (body_box_net): BoxNet(\n",
       "      (deconv): Sequential(\n",
       "        (0): ConvTranspose2d(2048, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "        (6): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU(inplace=True)\n",
       "      )\n",
       "      (bbox_center): Sequential(\n",
       "        (0): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (rhand_size): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=256, out_features=2, bias=True)\n",
       "      )\n",
       "      (lhand_size): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=256, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hand_roi_net): HandRoI(\n",
       "      (backbone): ResNetBackbone(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (hand_position_net): PositionNet(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(2048, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (coord_loss): CoordLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustom_eval_framework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge_evaluation_reports\n\u001b[1;32m----> 2\u001b[0m report_target_part1 \u001b[38;5;241m=\u001b[39m val_dataset_target_part1\u001b[38;5;241m.\u001b[39mperform_evaluation(\u001b[43mmodel\u001b[49m)\n\u001b[0;32m      3\u001b[0m report_target_part2 \u001b[38;5;241m=\u001b[39m val_dataset_target_part2\u001b[38;5;241m.\u001b[39mperform_evaluation(model)\n\u001b[0;32m      4\u001b[0m report_target \u001b[38;5;241m=\u001b[39m merge_evaluation_reports(report_target_part1, report_target_part2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from custom_eval_framework import merge_evaluation_reports\n",
    "report_target_part1 = val_dataset_target_part1.perform_evaluation(model)\n",
    "report_target_part2 = val_dataset_target_part2.perform_evaluation(model)\n",
    "report_target = merge_evaluation_reports(report_target_part1, report_target_part2)\n",
    "\n",
    "\"\"\"\n",
    "report_source_part1 = val_dataset_source_part1.perform_evaluation(model)\n",
    "report_source_part2 = val_dataset_source_part2.perform_evaluation(model)\n",
    "report_source = merge_evaluation_reports(report_source_part1, report_source_part2)\n",
    "\"\"\"\n",
    "report_target_cleaned_part1 = val_dataset_target_cleaned_part1.perform_evaluation(model)\n",
    "report_target_cleaned_part2 = val_dataset_target_cleaned_part2.perform_evaluation(model)\n",
    "report_target_cleaned = merge_evaluation_reports(report_target_cleaned_part1, report_target_cleaned_part2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_eval_framework import merge_evaluation_reports\n",
    "report_target_part1 = val_dataset_target_part1.perform_evaluation(model, adaptive_threshold=False)\n",
    "report_target_part2 = val_dataset_target_part2.perform_evaluation(model, adaptive_threshold=False)\n",
    "report_target_static = merge_evaluation_reports(report_target_part1, report_target_part2)\n",
    "\"\"\"\n",
    "report_source_part1 = val_dataset_source_part1.perform_evaluation(model, adaptive_threshold=False)\n",
    "report_source_part2 = val_dataset_source_part2.perform_evaluation(model, adaptive_threshold=False)\n",
    "report_source_static = merge_evaluation_reports(report_source_part1, report_source_part2)\n",
    "\"\"\"\n",
    "report_target_cleaned_part1 = val_dataset_target_cleaned_part1.perform_evaluation(model, adaptive_threshold=False)\n",
    "report_target_cleaned_part2 = val_dataset_target_cleaned_part2.perform_evaluation(model, adaptive_threshold=False)\n",
    "report_target_cleaned_static = merge_evaluation_reports(report_target_cleaned_part1, report_target_cleaned_part2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.585\n",
      "  Min:  0.000\n",
      "  Max:  1.000\n",
      "  Count: 170\n",
      "IOU:\n",
      "  Mean: 0.675\n",
      "  Min:  0.000\n",
      "  Max:  0.928\n",
      "  Count: 170\n",
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.705\n",
      "  Min:  0.190\n",
      "  Max:  1.000\n",
      "  Count: 47\n",
      "IOU:\n",
      "  Mean: 0.763\n",
      "  Min:  0.154\n",
      "  Max:  0.928\n",
      "  Count: 47\n"
     ]
    }
   ],
   "source": [
    "print(report_target)\n",
    "print(report_target_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.741\n",
      "  Min:  0.024\n",
      "  Max:  1.000\n",
      "  Count: 170\n",
      "IOU:\n",
      "  Mean: 0.676\n",
      "  Min:  0.029\n",
      "  Max:  0.928\n",
      "  Count: 170\n",
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.840\n",
      "  Min:  0.333\n",
      "  Max:  1.000\n",
      "  Count: 47\n",
      "IOU:\n",
      "  Mean: 0.763\n",
      "  Min:  0.154\n",
      "  Max:  0.928\n",
      "  Count: 47\n"
     ]
    }
   ],
   "source": [
    "print(report_target_static)\n",
    "print(report_target_cleaned_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.617\n",
      "  Min:  0.000\n",
      "  Max:  1.000\n",
      "  Count: 170\n",
      "IOU:\n",
      "  Mean: 0.712\n",
      "  Min:  0.000\n",
      "  Max:  0.935\n",
      "  Count: 170\n",
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.727\n",
      "  Min:  0.310\n",
      "  Max:  1.000\n",
      "  Count: 47\n",
      "IOU:\n",
      "  Mean: 0.788\n",
      "  Min:  0.427\n",
      "  Max:  0.933\n",
      "  Count: 47\n"
     ]
    }
   ],
   "source": [
    "print(report_target)\n",
    "print(report_target_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.780\n",
      "  Min:  0.024\n",
      "  Max:  1.000\n",
      "  Count: 170\n",
      "IOU:\n",
      "  Mean: 0.713\n",
      "  Min:  0.041\n",
      "  Max:  0.935\n",
      "  Count: 170\n",
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.874\n",
      "  Min:  0.500\n",
      "  Max:  1.000\n",
      "  Count: 47\n",
      "IOU:\n",
      "  Mean: 0.787\n",
      "  Min:  0.427\n",
      "  Max:  0.933\n",
      "  Count: 47\n"
     ]
    }
   ],
   "source": [
    "print(report_target_static)\n",
    "print(report_target_cleaned_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.656\n",
      "  Min:  0.024\n",
      "  Max:  1.000\n",
      "  Count: 170\n",
      "IOU:\n",
      "  Mean: 0.627\n",
      "  Min:  0.051\n",
      "  Max:  0.935\n",
      "  Count: 170\n",
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.777\n",
      "  Min:  0.357\n",
      "  Max:  1.000\n",
      "  Count: 47\n",
      "IOU:\n",
      "  Mean: 0.718\n",
      "  Min:  0.184\n",
      "  Max:  0.935\n",
      "  Count: 47\n"
     ]
    }
   ],
   "source": [
    "print(report_target_static)\n",
    "print(report_target_cleaned_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.934\n",
      "  Min:  0.643\n",
      "  Max:  1.000\n",
      "  Count: 170\n",
      "IOU:\n",
      "  Mean: 0.879\n",
      "  Min:  0.757\n",
      "  Max:  0.956\n",
      "  Count: 170\n"
     ]
    }
   ],
   "source": [
    "print(report_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.650\n",
      "  Min:  0.238\n",
      "  Max:  1.000\n",
      "  Count: 47\n",
      "IOU:\n",
      "  Mean: 0.718\n",
      "  Min:  0.184\n",
      "  Max:  0.935\n",
      "  Count: 47\n"
     ]
    }
   ],
   "source": [
    "print(report_target_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladi\\AppData\\Local\\Temp\\ipykernel_30908\\4063186805.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(source_ckpt)\n"
     ]
    }
   ],
   "source": [
    "from model_new_coral import get_model\n",
    "\n",
    "source_ckpt = r\"C:\\Users\\vladi\\RP\\InterWild\\output\\model_dump_old\\snapshot_0Ach0512.pth\"\n",
    "model = get_model(mode='test')\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "ckpt = torch.load(source_ckpt)\n",
    "load_info = model.load_state_dict(ckpt['network'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_eval_framework import merge_evaluation_reports\n",
    "report_target_part1 = val_dataset_target_part1.perform_evaluation(model)\n",
    "report_target_part2 = val_dataset_target_part2.perform_evaluation(model)\n",
    "report_target = merge_evaluation_reports(report_target_part1, report_target_part2)\n",
    "\n",
    "report_source_part1 = val_dataset_source_part1.perform_evaluation(model)\n",
    "report_source_part2 = val_dataset_source_part2.perform_evaluation(model)\n",
    "report_source = merge_evaluation_reports(report_source_part1, report_source_part2)\n",
    "\n",
    "report_target_cleaned_part1 = val_dataset_target_cleaned_part1.perform_evaluation(model)\n",
    "report_target_cleaned_part2 = val_dataset_target_cleaned_part2.perform_evaluation(model)\n",
    "report_target_cleaned = merge_evaluation_reports(report_target_cleaned_part1, report_target_cleaned_part2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.533\n",
      "  Min:  0.024\n",
      "  Max:  1.000\n",
      "  Count: 125\n",
      "IOU:\n",
      "  Mean: 0.627\n",
      "  Min:  0.044\n",
      "  Max:  0.927\n",
      "  Count: 125\n"
     ]
    }
   ],
   "source": [
    "print(report_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.938\n",
      "  Min:  0.571\n",
      "  Max:  1.000\n",
      "  Count: 125\n",
      "IOU:\n",
      "  Mean: 0.878\n",
      "  Min:  0.629\n",
      "  Max:  0.954\n",
      "  Count: 125\n"
     ]
    }
   ],
   "source": [
    "print(report_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.644\n",
      "  Min:  0.071\n",
      "  Max:  1.000\n",
      "  Count: 37\n",
      "IOU:\n",
      "  Mean: 0.704\n",
      "  Min:  0.044\n",
      "  Max:  0.923\n",
      "  Count: 37\n"
     ]
    }
   ],
   "source": [
    "print(report_target_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladi\\AppData\\Local\\Temp\\ipykernel_26824\\3216114335.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(source_ckpt)\n"
     ]
    }
   ],
   "source": [
    "from model_new_coral import get_model\n",
    "\n",
    "source_ckpt = r\"C:\\Users\\vladi\\RP\\InterWild\\output\\model_dump_old\\snapshot_8_pck535handcoral.pth\"\n",
    "model = get_model(mode='test')\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "ckpt = torch.load(source_ckpt)\n",
    "load_info = model.load_state_dict(ckpt['network'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_eval_framework import merge_evaluation_reports\n",
    "report_target_part1 = val_dataset_target_part1.perform_evaluation(model)\n",
    "report_target_part2 = val_dataset_target_part2.perform_evaluation(model)\n",
    "report_target = merge_evaluation_reports(report_target_part1, report_target_part2)\n",
    "\n",
    "report_source_part1 = val_dataset_source_part1.perform_evaluation(model)\n",
    "report_source_part2 = val_dataset_source_part2.perform_evaluation(model)\n",
    "report_source = merge_evaluation_reports(report_source_part1, report_source_part2)\n",
    "\n",
    "report_target_cleaned_part1 = val_dataset_target_cleaned_part1.perform_evaluation(model)\n",
    "report_target_cleaned_part2 = val_dataset_target_cleaned_part2.perform_evaluation(model)\n",
    "report_target_cleaned = merge_evaluation_reports(report_target_cleaned_part1, report_target_cleaned_part2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.498\n",
      "  Min:  0.024\n",
      "  Max:  1.000\n",
      "  Count: 170\n",
      "IOU:\n",
      "  Mean: 0.623\n",
      "  Min:  0.051\n",
      "  Max:  0.935\n",
      "  Count: 170\n"
     ]
    }
   ],
   "source": [
    "print(report_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.930\n",
      "  Min:  0.500\n",
      "  Max:  1.000\n",
      "  Count: 125\n",
      "IOU:\n",
      "  Mean: 0.857\n",
      "  Min:  0.627\n",
      "  Max:  0.946\n",
      "  Count: 125\n"
     ]
    }
   ],
   "source": [
    "print(report_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.696\n",
      "  Min:  0.190\n",
      "  Max:  1.000\n",
      "  Count: 37\n",
      "IOU:\n",
      "  Mean: 0.741\n",
      "  Min:  0.154\n",
      "  Max:  0.928\n",
      "  Count: 37\n"
     ]
    }
   ],
   "source": [
    "print(report_target_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladi\\AppData\\Local\\Temp\\ipykernel_30908\\3726844446.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  body_ckpt = torch.load(body_ckpt_path)\n",
      "C:\\Users\\vladi\\AppData\\Local\\Temp\\ipykernel_30908\\3726844446.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  hand_ckpt = torch.load(hand_ckpt_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: []\n",
      "Unexpected keys: []\n",
      "Saved combined model to: C:\\Users\\vladi\\RP\\InterWild\\output\\model_dump_old\\combined_model.pth\n"
     ]
    }
   ],
   "source": [
    "from model_new_coral import get_model\n",
    "import torch\n",
    "\n",
    "# Initialize model\n",
    "model = get_model(mode='test')\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "# Load first checkpoint for body parts\n",
    "body_ckpt_path = r\"C:\\Users\\vladi\\RP\\InterWild\\output\\model_dump_old\\snapshot_0Ach0512.pth\"\n",
    "body_ckpt = torch.load(body_ckpt_path)\n",
    "body_state_dict = {k: v for k, v in body_ckpt['network'].items() \n",
    "                   if k.startswith(('module.body_backbone', 'module.body_box_net'))}\n",
    "\n",
    "# Load second checkpoint for hand parts\n",
    "hand_ckpt_path = r\"C:\\Users\\vladi\\RP\\InterWild\\output\\model_dump_old\\snapshot_8_pck535handcoral.pth\"\n",
    "hand_ckpt = torch.load(hand_ckpt_path)\n",
    "hand_state_dict = {k: v for k, v in hand_ckpt['network'].items()\n",
    "                  if k.startswith(('module.hand_roi_net', 'module.hand_position_net'))}\n",
    "\n",
    "# Combine state dicts and load\n",
    "combined_state_dict = {}\n",
    "combined_state_dict.update(body_state_dict)\n",
    "combined_state_dict.update(hand_state_dict)\n",
    "\n",
    "# Load with strict=True to ensure all target keys exist\n",
    "load_info = model.load_state_dict(combined_state_dict, strict=True)\n",
    "\n",
    "# Verify loading\n",
    "print(\"Missing keys:\", load_info.missing_keys)  # Should be empty\n",
    "print(\"Unexpected keys:\", load_info.unexpected_keys)  # Should be empty\n",
    "\n",
    "# Save combined model to new checkpoint\n",
    "save_path = r\"C:\\Users\\vladi\\RP\\InterWild\\output\\model_dump_old\\combined_model.pth\"\n",
    "torch.save({\n",
    "    'epoch': 0,  # You can set appropriate values\n",
    "    'network': model.state_dict(),\n",
    "    'optimizer': None,  # Add optimizer state if needed\n",
    "    'meta': {'combined_from': [body_ckpt_path, hand_ckpt_path]}\n",
    "}, save_path)\n",
    "print(f\"Saved combined model to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_eval_framework import merge_evaluation_reports\n",
    "report_target_part1 = val_dataset_target_part1.perform_evaluation(model)\n",
    "report_target_part2 = val_dataset_target_part2.perform_evaluation(model)\n",
    "report_target = merge_evaluation_reports(report_target_part1, report_target_part2)\n",
    "\n",
    "report_source_part1 = val_dataset_source_part1.perform_evaluation(model)\n",
    "report_source_part2 = val_dataset_source_part2.perform_evaluation(model)\n",
    "report_source = merge_evaluation_reports(report_source_part1, report_source_part2)\n",
    "\n",
    "report_target_cleaned_part1 = val_dataset_target_cleaned_part1.perform_evaluation(model)\n",
    "report_target_cleaned_part2 = val_dataset_target_cleaned_part2.perform_evaluation(model)\n",
    "report_target_cleaned = merge_evaluation_reports(report_target_cleaned_part1, report_target_cleaned_part2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.586\n",
      "  Min:  0.024\n",
      "  Max:  1.000\n",
      "  Count: 125\n",
      "IOU:\n",
      "  Mean: 0.648\n",
      "  Min:  0.025\n",
      "  Max:  0.967\n",
      "  Count: 125\n"
     ]
    }
   ],
   "source": [
    "print(report_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.933\n",
      "  Min:  0.714\n",
      "  Max:  1.000\n",
      "  Count: 125\n",
      "IOU:\n",
      "  Mean: 0.855\n",
      "  Min:  0.732\n",
      "  Max:  0.958\n",
      "  Count: 125\n"
     ]
    }
   ],
   "source": [
    "print(report_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.718\n",
      "  Min:  0.310\n",
      "  Max:  1.000\n",
      "  Count: 37\n",
      "IOU:\n",
      "  Mean: 0.776\n",
      "  Min:  0.427\n",
      "  Max:  0.933\n",
      "  Count: 37\n"
     ]
    }
   ],
   "source": [
    "print(report_target_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_target = torch.utils.data.ConcatDataset([val_dataset_target_part1, val_dataset_target_part2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladi\\AppData\\Local\\Temp\\ipykernel_26824\\4083501755.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(source_ckpt)\n"
     ]
    }
   ],
   "source": [
    "from model_new import get_model\n",
    "\n",
    "source_ckpt = r\"C:\\Users\\vladi\\RP\\InterWild\\output\\model_dump_old\\combined_model.pth\"\n",
    "model = get_model(mode='test')\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "ckpt = torch.load(source_ckpt)\n",
    "load_info = model.load_state_dict(ckpt['network'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# Put all BatchNorm layers in train mode while keeping the model in eval mode\n",
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module.train()\n",
    "        module.momentum = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered __getitem__\n",
      "[492. 364. 822. 642.] [494. 710. 828. 994.]\n",
      "Entered __getitem__\n",
      "[458. 416. 808. 676.] [ 452.  786.  796. 1058.]\n",
      "Entered __getitem__\n",
      "[438. 396. 784. 642.] [ 420.  746.  784. 1020.]\n",
      "Entered __getitem__\n",
      "[466. 316. 804. 544.] [468. 654. 814. 934.]\n",
      "Entered __getitem__\n",
      "[476. 358. 820. 588.] [466. 684. 806. 956.]\n",
      "Entered __getitem__\n",
      "[348. 300. 708. 628.] [ 308.          720.          694.66666667 1066.66666667]\n",
      "Entered __getitem__\n",
      "[345.33333333 324.         721.33333333 670.66666667] [ 341.33333333  761.33333333  734.66666667 1101.33333333]\n",
      "Entered __getitem__\n",
      "[398.66666667 318.66666667 793.33333333 632.        ] [ 406.66666667  677.33333333  792.         1034.66666667]\n",
      "Entered __getitem__\n",
      "[398.66666667 294.66666667 778.66666667 608.        ] [ 382.66666667  722.66666667  766.66666667 1078.66666667]\n",
      "Entered __getitem__\n",
      "[381.33333333 265.33333333 753.33333333 572.        ] [ 425.33333333  708.          801.33333333 1005.33333333]\n",
      "Entered __getitem__\n",
      "[496. 410. 802. 686.] [ 464.  772.  804. 1040.]\n",
      "Entered __getitem__\n",
      "[440.         301.33333333 832.         600.        ] [ 442.66666667  729.33333333  822.66666667 1060.        ]\n",
      "Entered __getitem__\n",
      "[472.         317.33333333 842.66666667 637.33333333] [ 508.          710.66666667  896.         1042.66666667]\n",
      "Entered __getitem__\n",
      "[412.         326.66666667 793.33333333 654.66666667] [ 441.33333333  794.66666667  813.33333333 1110.66666667]\n",
      "Entered __getitem__\n",
      "[465.33333333 350.66666667 849.33333333 637.33333333] [ 488.          712.          862.66666667 1029.33333333]\n",
      "Entered __getitem__\n",
      "[413.33333333 413.33333333 796.         705.33333333] [ 428.          793.33333333  804.         1124.        ]\n",
      "Entered __getitem__\n",
      "[504.         280.         866.66666667 584.        ] [ 518.66666667  684.          896.         1012.        ]\n",
      "Entered __getitem__\n",
      "[425.33333333 333.33333333 794.66666667 638.66666667] [ 453.33333333  742.66666667  840.         1081.33333333]\n",
      "Entered __getitem__\n",
      "[453.33333333 294.66666667 838.66666667 609.33333333] [ 502.66666667  666.66666667  869.33333333 1016.        ]\n",
      "Entered __getitem__\n",
      "[425.33333333 309.33333333 809.33333333 632.        ] [ 434.66666667  676.          825.33333333 1016.        ]\n",
      "Entered __getitem__\n",
      "[381.33333333 318.66666667 745.33333333 632.        ] [ 352.          710.66666667  737.33333333 1069.33333333]\n",
      "Entered __getitem__\n",
      "[484. 302. 830. 568.] [458. 708. 830. 980.]\n",
      "Entered __getitem__\n",
      "[522.66666667 297.33333333 874.66666667 630.66666667] [ 526.66666667  678.66666667  901.33333333 1033.33333333]\n",
      "Entered __getitem__\n",
      "[421.21212121 245.45454545 801.51515152 543.93939394] [ 442.42424242  683.33333333  833.33333333 1003.03030303]\n",
      "Entered __getitem__\n",
      "[537.87878788 268.18181818 934.84848485 568.18181818] [572.72727273 642.42424242 969.6969697  972.72727273]\n",
      "Entered __getitem__\n",
      "[490.90909091 328.78787879 874.24242424 640.90909091] [ 471.21212121  725.75757576  878.78787879 1065.15151515]\n",
      "Entered __getitem__\n",
      "[504.54545455 290.90909091 898.48484848 559.09090909] [ 528.78787879  725.75757576  924.24242424 1057.57575758]\n",
      "Entered __getitem__\n",
      "[484.84848485 404.54545455 892.42424242 704.54545455] [ 527.27272727  831.81818182  918.18181818 1134.84848485]\n",
      "Entered __getitem__\n",
      "[519.6969697  331.81818182 918.18181818 625.75757576] [ 560.60606061  695.45454545  965.15151515 1018.18181818]\n",
      "Entered __getitem__\n",
      "[507.57575758 330.3030303  906.06060606 627.27272727] [ 586.36363636  683.33333333  974.24242424 1022.72727273]\n",
      "Entered __getitem__\n",
      "[437.87878788 272.72727273 825.75757576 548.48484848] [463.63636364 633.33333333 857.57575758 919.6969697 ]\n",
      "Entered __getitem__\n",
      "[454.54545455 281.81818182 843.93939394 575.75757576] [483.33333333 665.15151515 875.75757576 954.54545455]\n",
      "Entered __getitem__\n",
      "[418. 200. 772. 474.] [438. 588. 774. 894.]\n",
      "Entered __getitem__\n",
      "[413.63636364 363.63636364 801.51515152 656.06060606] [ 427.27272727  703.03030303  840.90909091 1022.72727273]\n",
      "Entered __getitem__\n",
      "[463.63636364 319.6969697  857.57575758 615.15151515] [490.90909091 643.93939394 889.39393939 939.39393939]\n",
      "Entered __getitem__\n",
      "[392.42424242 309.09090909 781.81818182 550.        ] [421.21212121 601.51515152 815.15151515 898.48484848]\n",
      "Entered __getitem__\n",
      "[389.39393939 342.42424242 774.24242424 598.48484848] [413.63636364 659.09090909 836.36363636 953.03030303]\n",
      "Entered __getitem__\n",
      "[402. 320. 862. 654.] [ 434.  686.  888. 1066.]\n",
      "Entered __getitem__\n",
      "[284. 328. 748. 662.] [ 306.  744.  766. 1132.]\n",
      "Entered __getitem__\n",
      "[312. 304. 762. 646.] [ 346.  686.  808. 1110.]\n",
      "Entered __getitem__\n",
      "[282. 348. 748. 704.] [ 294.  766.  756. 1164.]\n",
      "Entered __getitem__\n",
      "[308. 278. 766. 596.] [ 328.  686.  776. 1062.]\n",
      "Entered __getitem__\n",
      "[280. 280. 744. 624.] [ 282.  652.  748. 1038.]\n",
      "Entered __getitem__\n",
      "[442. 302. 794. 590.] [ 474.  698.  802. 1002.]\n",
      "Entered __getitem__\n",
      "[372. 344. 826. 656.] [ 374.  714.  848. 1044.]\n",
      "Entered __getitem__\n",
      "[316. 392. 760. 708.] [ 340.  756.  776. 1074.]\n",
      "Entered __getitem__\n",
      "[408. 270. 848. 588.] [452. 666. 860. 968.]\n",
      "Entered __getitem__\n",
      "[284. 324. 754. 648.] [ 332.  720.  778. 1048.]\n",
      "Entered __getitem__\n",
      "[412. 212. 882. 518.] [440. 570. 868. 950.]\n",
      "Entered __getitem__\n",
      "[344. 330. 802. 654.] [ 364.  716.  832. 1064.]\n",
      "Entered __getitem__\n",
      "[472. 280. 934. 580.] [ 506.  650.  964. 1040.]\n",
      "Entered __getitem__\n",
      "[372. 326. 826. 658.] [ 430.  704.  854. 1078.]\n",
      "Entered __getitem__\n",
      "[518. 250. 982. 560.] [ 532.  602. 1006.  988.]\n",
      "Entered __getitem__\n",
      "[446. 294. 904. 592.] [ 476.  722.  938. 1082.]\n",
      "Entered __getitem__\n",
      "[484. 274. 818. 536.] [470. 638. 818. 904.]\n",
      "Entered __getitem__\n",
      "[323.33333333 246.66666667 743.33333333 670.        ] [ 410.          693.33333333  811.66666667 1120.        ]\n",
      "Entered __getitem__\n",
      "[305.         316.66666667 683.33333333 768.33333333] [ 258.33333333  781.66666667  690.         1211.66666667]\n",
      "Entered __getitem__\n",
      "[276.66666667 261.66666667 683.33333333 700.        ] [ 310.          743.33333333  731.66666667 1208.33333333]\n",
      "Entered __getitem__\n",
      "[256.66666667 236.66666667 645.         676.66666667] [ 245.          723.33333333  670.         1183.33333333]\n",
      "Entered __getitem__\n",
      "[381.66666667 171.66666667 768.33333333 648.33333333] [ 400.          676.66666667  806.66666667 1131.66666667]\n",
      "Entered __getitem__\n",
      "[273.33333333 201.66666667 691.66666667 655.        ] [ 313.33333333  715.          711.66666667 1151.66666667]\n",
      "Entered __getitem__\n",
      "[328.33333333 191.66666667 715.         673.33333333] [ 370.          743.33333333  786.66666667 1183.33333333]\n",
      "Entered __getitem__\n",
      "[286.66666667 265.         666.66666667 731.66666667] [ 301.66666667  801.66666667  708.33333333 1230.        ]\n",
      "Entered __getitem__\n",
      "[268.33333333 306.66666667 703.33333333 766.66666667] [ 276.66666667  791.66666667  700.         1215.        ]\n",
      "Entered __getitem__\n",
      "[291.66666667 315.         711.66666667 778.33333333] [ 286.66666667  848.33333333  713.33333333 1278.33333333]\n",
      "Entered __getitem__\n",
      "[408. 250. 736. 524.] [400. 628. 738. 900.]\n",
      "Entered __getitem__\n",
      "[321.66666667 330.         733.33333333 806.66666667] [ 361.66666667  856.66666667  758.33333333 1286.66666667]\n",
      "Entered __getitem__\n",
      "[296.66666667 258.33333333 721.66666667 735.        ] [ 370.          783.33333333  766.66666667 1181.66666667]\n",
      "Entered __getitem__\n",
      "[296.66666667 313.33333333 723.33333333 781.66666667] [ 346.66666667  826.66666667  756.66666667 1253.33333333]\n",
      "Entered __getitem__\n",
      "[345.         228.33333333 758.33333333 713.33333333] [ 405.          740.          793.33333333 1176.66666667]\n",
      "Entered __getitem__\n",
      "[300.         306.66666667 701.66666667 780.        ] [ 323.33333333  810.          723.33333333 1236.66666667]\n",
      "Entered __getitem__\n",
      "[340.         226.66666667 738.33333333 700.        ] [ 376.66666667  811.66666667  796.66666667 1258.33333333]\n",
      "Entered __getitem__\n",
      "[486. 280. 818. 544.] [510. 692. 834. 974.]\n",
      "Entered __getitem__\n",
      "[434. 308. 776. 572.] [478. 726. 792. 998.]\n",
      "Entered __getitem__\n",
      "[530.3030303  356.06060606 909.09090909 612.12121212] [557.57575758 687.87878788 956.06060606 978.78787879]\n",
      "Entered __getitem__\n",
      "[372.72727273 334.84848485 766.66666667 577.27272727] [413.63636364 671.21212121 796.96969697 942.42424242]\n",
      "Entered __getitem__\n",
      "[450. 324. 796. 548.] [472. 652. 816. 912.]\n",
      "Entered __getitem__\n",
      "[507.57575758 309.09090909 892.42424242 612.12121212] [539.39393939 703.03030303 939.39393939 998.48484848]\n",
      "Entered __getitem__\n",
      "[434. 338. 768. 598.] [424. 680. 774. 958.]\n",
      "Entered __getitem__\n",
      "[544. 340. 870. 622.] [528. 688. 870. 964.]\n",
      "Entered __getitem__\n",
      "[274.28571429 491.42857143 678.57142857 912.85714286] [ 232.85714286  990.          655.71428571 1341.42857143]\n",
      "Entered __getitem__\n",
      "[381.42857143 461.42857143 800.         891.42857143] [ 360.          964.28571429  780.         1317.14285714]\n",
      "Entered __getitem__\n",
      "[387.14285714 577.14285714 797.14285714 985.71428571] [ 377.14285714 1034.28571429  795.71428571 1382.85714286]\n",
      "Entered __getitem__\n",
      "[384.28571429 530.         792.85714286 947.14285714] [ 365.71428571 1000.          778.57142857 1368.57142857]\n",
      "Entered __getitem__\n",
      "[381.42857143 558.57142857 781.42857143 991.42857143] [ 342.85714286 1040.          758.57142857 1398.57142857]\n",
      "Entered __getitem__\n",
      "[374.28571429 560.         780.         962.85714286] [ 352.85714286 1020.          767.14285714 1345.71428571]\n",
      "Entered __getitem__\n",
      "[ 407.14285714  660.          812.85714286 1020.        ] [ 357.14285714 1084.28571429  771.42857143 1407.14285714]\n",
      "Entered __getitem__\n",
      "[ 378.57142857  625.71428571  784.28571429 1002.85714286] [ 350.         1060.          764.28571429 1391.42857143]\n",
      "Entered __getitem__\n",
      "[ 445.71428571  588.57142857  844.28571429 1010.        ] [ 421.42857143 1067.14285714  832.85714286 1388.57142857]\n",
      "Entered __getitem__\n",
      "[ 437.14285714  614.28571429  844.28571429 1007.14285714] [ 405.71428571 1041.42857143  807.14285714 1324.28571429]\n",
      "Entered __getitem__\n",
      "[438.57142857 597.14285714 845.71428571 988.57142857] [ 398.57142857 1037.14285714  798.57142857 1358.57142857]\n",
      "Entered __getitem__\n",
      "[400.         535.71428571 800.         944.28571429] [ 354.28571429  997.14285714  760.         1340.        ]\n",
      "Entered __getitem__\n",
      "[440.         577.14285714 851.42857143 975.71428571] [ 398.57142857 1017.14285714  802.85714286 1358.57142857]\n",
      "Entered __getitem__\n",
      "[440.         537.14285714 838.57142857 955.71428571] [ 432.85714286 1008.57142857  837.14285714 1340.        ]\n",
      "Entered __getitem__\n",
      "[432.85714286 571.42857143 824.28571429 972.85714286] [ 398.57142857 1040.          795.71428571 1371.42857143]\n",
      "Entered __getitem__\n",
      "[322.85714286 525.71428571 651.42857143 804.28571429] [ 294.28571429  855.71428571  631.42857143 1152.85714286]\n",
      "Entered __getitem__\n",
      "[338.57142857 484.28571429 678.57142857 764.28571429] [ 334.28571429  802.85714286  664.28571429 1068.57142857]\n",
      "Entered __getitem__\n",
      "[325.71428571 527.14285714 641.42857143 807.14285714] [ 290.          831.42857143  610.         1097.14285714]\n",
      "Entered __getitem__\n",
      "[321.42857143 540.         660.         810.        ] [ 317.14285714  858.57142857  641.42857143 1142.85714286]\n",
      "Entered __getitem__\n",
      "[287.14285714 520.         622.85714286 801.42857143] [ 274.28571429  837.14285714  600.         1122.85714286]\n",
      "Entered __getitem__\n",
      "[278.57142857 488.57142857 615.71428571 764.28571429] [ 258.57142857  830.          591.42857143 1105.71428571]\n",
      "Entered __getitem__\n",
      "[270.         521.42857143 602.85714286 804.28571429] [ 262.85714286  838.57142857  598.57142857 1125.71428571]\n",
      "Entered __getitem__\n",
      "[272.85714286 518.57142857 612.85714286 804.28571429] [ 261.42857143  842.85714286  594.28571429 1100.        ]\n",
      "Entered __getitem__\n",
      "[330.         525.71428571 680.         810.        ] [ 322.85714286  861.42857143  652.85714286 1137.14285714]\n",
      "Entered __getitem__\n",
      "[332.85714286 541.42857143 682.85714286 822.85714286] [ 330.          874.28571429  658.57142857 1158.57142857]\n",
      "Entered __getitem__\n",
      "[327.14285714 512.85714286 658.57142857 801.42857143] [ 305.71428571  875.71428571  640.         1160.        ]\n",
      "Entered __getitem__\n",
      "[308.57142857 525.71428571 654.28571429 800.        ] [ 305.71428571  854.28571429  637.14285714 1147.14285714]\n",
      "Entered __getitem__\n",
      "[312.85714286 481.42857143 647.14285714 760.        ] [ 300.          805.71428571  637.14285714 1085.71428571]\n",
      "Entered __getitem__\n",
      "[268.57142857 492.85714286 615.71428571 770.        ] [ 265.71428571  812.85714286  608.57142857 1072.85714286]\n",
      "Entered __getitem__\n",
      "[285.71428571 508.57142857 617.14285714 792.85714286] [ 267.14285714  828.57142857  607.14285714 1090.        ]\n",
      "Entered __getitem__\n",
      "[427.14285714 330.         850.         730.        ] [ 370.          821.42857143  797.14285714 1180.        ]\n",
      "Entered __getitem__\n",
      "[407.14285714 401.42857143 821.42857143 758.57142857] [ 351.42857143  847.14285714  781.42857143 1192.85714286]\n",
      "Entered __getitem__\n",
      "[458.57142857 502.85714286 844.28571429 820.        ] [ 400.          894.28571429  822.85714286 1251.42857143]\n",
      "Entered __getitem__\n",
      "[417.14285714 360.         794.28571429 734.28571429] [ 361.42857143  820.          792.85714286 1208.57142857]\n",
      "Entered __getitem__\n",
      "[434.28571429 460.         838.57142857 778.57142857] [ 375.71428571  870.          792.85714286 1227.14285714]\n",
      "Entered __getitem__\n",
      "[388.57142857 342.85714286 780.         682.85714286] [ 325.71428571  828.57142857  742.85714286 1190.        ]\n",
      "Entered __getitem__\n",
      "[401.42857143 395.71428571 812.85714286 781.42857143] [ 375.71428571  868.57142857  800.         1235.71428571]\n",
      "Entered __getitem__\n",
      "[400.         511.42857143 852.85714286 841.42857143] [ 390.          905.71428571  811.42857143 1264.28571429]\n",
      "Entered __getitem__\n",
      "[421.42857143 471.42857143 840.         822.85714286] [ 388.57142857  881.42857143  801.42857143 1231.42857143]\n",
      "Entered __getitem__\n",
      "[391.42857143 482.85714286 801.42857143 808.57142857] [ 365.71428571  875.71428571  778.57142857 1247.14285714]\n",
      "Entered __getitem__\n",
      "[390.         494.28571429 811.42857143 802.85714286] [ 355.71428571  882.85714286  777.14285714 1235.71428571]\n",
      "Entered __getitem__\n",
      "[435.71428571 522.85714286 832.85714286 851.42857143] [ 394.28571429  908.57142857  804.28571429 1272.85714286]\n",
      "Entered __getitem__\n",
      "[430.         488.57142857 855.71428571 817.14285714] [ 392.85714286  867.14285714  805.71428571 1220.        ]\n",
      "Entered __getitem__\n",
      "[372.85714286 534.28571429 790.         842.85714286] [ 355.71428571  898.57142857  761.42857143 1268.57142857]\n",
      "Entered __getitem__\n",
      "[425.71428571 522.85714286 847.14285714 832.85714286] [ 388.57142857  901.42857143  792.85714286 1230.        ]\n",
      "Entered __getitem__\n",
      "[274.28571429 491.42857143 678.57142857 912.85714286] [ 232.85714286  990.          655.71428571 1341.42857143]\n",
      "Entered __getitem__\n",
      "[381.42857143 461.42857143 800.         891.42857143] [ 360.          964.28571429  780.         1317.14285714]\n",
      "Entered __getitem__\n",
      "[387.14285714 577.14285714 797.14285714 985.71428571] [ 377.14285714 1034.28571429  795.71428571 1382.85714286]\n",
      "Entered __getitem__\n",
      "[384.28571429 530.         792.85714286 947.14285714] [ 365.71428571 1000.          778.57142857 1368.57142857]\n",
      "Entered __getitem__\n",
      "[381.42857143 558.57142857 781.42857143 991.42857143] [ 342.85714286 1040.          758.57142857 1398.57142857]\n",
      "Entered __getitem__\n",
      "[374.28571429 560.         780.         962.85714286] [ 352.85714286 1020.          767.14285714 1345.71428571]\n",
      "Entered __getitem__\n",
      "[ 407.14285714  660.          812.85714286 1020.        ] [ 357.14285714 1084.28571429  771.42857143 1407.14285714]\n",
      "Entered __getitem__\n",
      "[ 378.57142857  625.71428571  784.28571429 1002.85714286] [ 350.         1060.          764.28571429 1391.42857143]\n",
      "Entered __getitem__\n",
      "[ 445.71428571  588.57142857  844.28571429 1010.        ] [ 421.42857143 1067.14285714  832.85714286 1388.57142857]\n",
      "Entered __getitem__\n",
      "[ 437.14285714  614.28571429  844.28571429 1007.14285714] [ 405.71428571 1041.42857143  807.14285714 1324.28571429]\n",
      "Entered __getitem__\n",
      "[438.57142857 597.14285714 845.71428571 988.57142857] [ 398.57142857 1037.14285714  798.57142857 1358.57142857]\n",
      "Entered __getitem__\n",
      "[400.         535.71428571 800.         944.28571429] [ 354.28571429  997.14285714  760.         1340.        ]\n",
      "Entered __getitem__\n",
      "[440.         577.14285714 851.42857143 975.71428571] [ 398.57142857 1017.14285714  802.85714286 1358.57142857]\n",
      "Entered __getitem__\n",
      "[440.         537.14285714 838.57142857 955.71428571] [ 432.85714286 1008.57142857  837.14285714 1340.        ]\n",
      "Entered __getitem__\n",
      "[432.85714286 571.42857143 824.28571429 972.85714286] [ 398.57142857 1040.          795.71428571 1371.42857143]\n",
      "Entered __getitem__\n",
      "[322.85714286 525.71428571 651.42857143 804.28571429] [ 294.28571429  855.71428571  631.42857143 1152.85714286]\n",
      "Entered __getitem__\n",
      "[338.57142857 484.28571429 678.57142857 764.28571429] [ 334.28571429  802.85714286  664.28571429 1068.57142857]\n",
      "Entered __getitem__\n",
      "[325.71428571 527.14285714 641.42857143 807.14285714] [ 290.          831.42857143  610.         1097.14285714]\n",
      "Entered __getitem__\n",
      "[321.42857143 540.         660.         810.        ] [ 317.14285714  858.57142857  641.42857143 1142.85714286]\n",
      "Entered __getitem__\n",
      "[287.14285714 520.         622.85714286 801.42857143] [ 274.28571429  837.14285714  600.         1122.85714286]\n",
      "Entered __getitem__\n",
      "[278.57142857 488.57142857 615.71428571 764.28571429] [ 258.57142857  830.          591.42857143 1105.71428571]\n",
      "Entered __getitem__\n",
      "[270.         521.42857143 602.85714286 804.28571429] [ 262.85714286  838.57142857  598.57142857 1125.71428571]\n",
      "Entered __getitem__\n",
      "[272.85714286 518.57142857 612.85714286 804.28571429] [ 261.42857143  842.85714286  594.28571429 1100.        ]\n",
      "Entered __getitem__\n",
      "[330.         525.71428571 680.         810.        ] [ 322.85714286  861.42857143  652.85714286 1137.14285714]\n",
      "Entered __getitem__\n",
      "[332.85714286 541.42857143 682.85714286 822.85714286] [ 330.          874.28571429  658.57142857 1158.57142857]\n",
      "Entered __getitem__\n",
      "[327.14285714 512.85714286 658.57142857 801.42857143] [ 305.71428571  875.71428571  640.         1160.        ]\n",
      "Entered __getitem__\n",
      "[308.57142857 525.71428571 654.28571429 800.        ] [ 305.71428571  854.28571429  637.14285714 1147.14285714]\n",
      "Entered __getitem__\n",
      "[312.85714286 481.42857143 647.14285714 760.        ] [ 300.          805.71428571  637.14285714 1085.71428571]\n",
      "Entered __getitem__\n",
      "[268.57142857 492.85714286 615.71428571 770.        ] [ 265.71428571  812.85714286  608.57142857 1072.85714286]\n",
      "Entered __getitem__\n",
      "[285.71428571 508.57142857 617.14285714 792.85714286] [ 267.14285714  828.57142857  607.14285714 1090.        ]\n",
      "Entered __getitem__\n",
      "[427.14285714 330.         850.         730.        ] [ 370.          821.42857143  797.14285714 1180.        ]\n",
      "Entered __getitem__\n",
      "[407.14285714 401.42857143 821.42857143 758.57142857] [ 351.42857143  847.14285714  781.42857143 1192.85714286]\n",
      "Entered __getitem__\n",
      "[458.57142857 502.85714286 844.28571429 820.        ] [ 400.          894.28571429  822.85714286 1251.42857143]\n",
      "Entered __getitem__\n",
      "[417.14285714 360.         794.28571429 734.28571429] [ 361.42857143  820.          792.85714286 1208.57142857]\n",
      "Entered __getitem__\n",
      "[434.28571429 460.         838.57142857 778.57142857] [ 375.71428571  870.          792.85714286 1227.14285714]\n",
      "Entered __getitem__\n",
      "[388.57142857 342.85714286 780.         682.85714286] [ 325.71428571  828.57142857  742.85714286 1190.        ]\n",
      "Entered __getitem__\n",
      "[401.42857143 395.71428571 812.85714286 781.42857143] [ 375.71428571  868.57142857  800.         1235.71428571]\n",
      "Entered __getitem__\n",
      "[400.         511.42857143 852.85714286 841.42857143] [ 390.          905.71428571  811.42857143 1264.28571429]\n",
      "Entered __getitem__\n",
      "[421.42857143 471.42857143 840.         822.85714286] [ 388.57142857  881.42857143  801.42857143 1231.42857143]\n",
      "Entered __getitem__\n",
      "[391.42857143 482.85714286 801.42857143 808.57142857] [ 365.71428571  875.71428571  778.57142857 1247.14285714]\n",
      "Entered __getitem__\n",
      "[390.         494.28571429 811.42857143 802.85714286] [ 355.71428571  882.85714286  777.14285714 1235.71428571]\n",
      "Entered __getitem__\n",
      "[435.71428571 522.85714286 832.85714286 851.42857143] [ 394.28571429  908.57142857  804.28571429 1272.85714286]\n",
      "Entered __getitem__\n",
      "[430.         488.57142857 855.71428571 817.14285714] [ 392.85714286  867.14285714  805.71428571 1220.        ]\n",
      "Entered __getitem__\n",
      "[372.85714286 534.28571429 790.         842.85714286] [ 355.71428571  898.57142857  761.42857143 1268.57142857]\n",
      "Entered __getitem__\n",
      "[425.71428571 522.85714286 847.14285714 832.85714286] [ 388.57142857  901.42857143  792.85714286 1230.        ]\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset_target, batch_size=32, shuffle=False)\n",
    "\n",
    "for batch in val_loader:\n",
    "    source_inputs, source_targets, source_meta_info = batch\n",
    "    for k in source_inputs:\n",
    "        source_inputs[k] = source_inputs[k].cuda()\n",
    "    for k in source_targets:\n",
    "        source_targets[k] = source_targets[k].cuda()\n",
    "    for k in source_meta_info:\n",
    "        # If meta_info holds Tensors, also send to device\n",
    "        # Otherwise skip\n",
    "        if isinstance(source_meta_info[k], torch.Tensor):\n",
    "            source_meta_info[k] = source_meta_info[k].cuda()\n",
    "\n",
    "    outputs = model.forward(\n",
    "        source_inputs,\n",
    "        source_targets,\n",
    "        source_meta_info,  # Pass combined dictionary as meta_info\n",
    "        \"test\",  # Pass 'train' as the mode\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up CUDA memory\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[471.05744361877436, 435.5885982513428, 817.8269004821777, 689.2771625518799] [494.0, 710.0, 828.0, 994.0]\n",
      "[464.3275451660156, 478.3582019805908, 794.5772552490234, 720.7719612121582] [452.0, 785.9999999999999, 796.0, 1058.0]\n",
      "[447.91500091552734, 442.42509841918945, 785.9622573852539, 696.7115592956543] [420.0, 746.0000000000001, 784.0, 1020.0]\n",
      "[461.24613761901855, 644.9626922607422, 752.1302032470703, 880.1889038085938] [468.0, 654.0, 814.0, 934.0]\n",
      "[467.6031875610351, 677.5645351409912, 748.10302734375, 882.9944515228271] [466.0, 684.0, 806.0, 956.0]\n",
      "[319.67519760131836, 523.6223888397217, 672.4281692504883, 902.8899192810059] [308.0, 720.0, 694.6666666666666, 1066.6666666666665]\n",
      "[336.70263290405273, 377.6111698150635, 723.3352947235107, 690.9047698974609] [341.3333333333333, 761.3333333333333, 734.6666666666666, 1101.3333333333333]\n",
      "[420.55277824401855, 669.8623466491699, 778.1089210510253, 1026.400966644287] [406.6666666666667, 677.3333333333334, 792.0, 1034.6666666666667]\n",
      "[377.96650886535645, 684.5788764953613, 755.3016471862793, 1048.0833435058594] [382.66666666666663, 722.6666666666667, 766.6666666666667, 1078.6666666666667]\n",
      "[353.63170623779297, 326.95664405822754, 754.1842174530029, 630.7641506195068] [425.3333333333333, 708.0, 801.3333333333334, 1005.3333333333334]\n",
      "[496.01237297058105, 529.5398139953613, 754.1476535797119, 762.6000881195068] [464.0, 772.0, 804.0, 1040.0]\n",
      "[422.8968143463135, 355.8178997039795, 817.9491233825682, 658.6209297180176] [442.6666666666667, 729.3333333333334, 822.6666666666666, 1060.0]\n",
      "[449.3489742279053, 693.4374618530273, 848.7068939208984, 989.6928977966309] [508.0, 710.6666666666666, 896.0, 1042.6666666666667]\n",
      "[431.9955539703369, 729.9251174926758, 798.2732105255127, 1055.5782508850098] [441.33333333333337, 794.6666666666666, 813.3333333333334, 1110.6666666666665]\n",
      "[436.31747245788574, 380.513277053833, 828.2266616821288, 709.9184989929199] [488.0, 712.0, 862.6666666666666, 1029.3333333333333]\n",
      "[401.7909622192383, 662.7377128601074, 777.7444839477539, 1061.3910484313965] [428.0, 793.3333333333334, 804.0, 1124.0]\n",
      "[467.56550788879395, 648.9356231689453, 857.2470474243163, 991.2505531311035] [518.6666666666666, 684.0, 896.0, 1011.9999999999999]\n",
      "[448.05456161499023, 703.6398124694824, 825.4728698730469, 1008.870735168457] [453.3333333333333, 742.6666666666666, 840.0, 1081.3333333333333]\n",
      "[432.8957462310791, 603.0194664001465, 844.3722724914551, 1009.7769355773926] [502.6666666666667, 666.6666666666666, 869.3333333333333, 1016.0000000000001]\n",
      "[431.2075424194336, 579.4224643707275, 793.9152431488037, 955.2865505218506] [434.66666666666663, 676.0, 825.3333333333333, 1016.0000000000001]\n",
      "[347.0968794822693, 748.6189556121826, 654.1862297058104, 1040.5332469940186] [352.0, 710.6666666666666, 737.3333333333333, 1069.3333333333333]\n",
      "[478.0492115020752, 405.3529357910156, 796.5210628509521, 606.8908596038818] [458.0, 708.0, 830.0, 980.0]\n",
      "[429.1654586791992, 678.0473327636719, 873.7960624694823, 1008.8791465759277] [526.6666666666666, 678.6666666666666, 901.3333333333334, 1033.3333333333333]\n",
      "[426.4520072937012, 342.71541595458984, 796.3912010192871, 573.9316177368164] [442.4242424242424, 683.3333333333333, 833.3333333333331, 1003.0303030303029]\n",
      "[528.4361171722412, 357.51837730407715, 890.3809547424316, 595.8793830871582] [572.7272727272727, 642.4242424242424, 969.6969696969696, 972.7272727272725]\n",
      "[504.2058563232422, 732.29172706604, 828.3974647521973, 949.030179977417] [471.2121212121212, 725.7575757575758, 878.7878787878788, 1065.151515151515]\n",
      "[534.4264984130859, 738.1910419464111, 875.3826427459717, 957.8789806365967] [528.7878787878788, 725.7575757575758, 924.2424242424241, 1057.5757575757575]\n",
      "[533.7467193603516, 595.8038520812988, 814.5558929443358, 871.5478134155273] [527.2727272727273, 831.8181818181818, 918.1818181818181, 1134.8484848484848]\n",
      "[567.9504203796387, 720.3821182250977, 841.0305404663086, 951.401252746582] [560.6060606060605, 695.4545454545454, 965.151515151515, 1018.181818181818]\n",
      "[581.5129137039185, 726.7095565795898, 873.6664581298828, 950.6186485290527] [586.3636363636364, 683.3333333333333, 974.2424242424241, 1022.7272727272727]\n",
      "[476.92946434020996, 404.7952079772949, 743.7979316711426, 610.2011775970459] [463.63636363636357, 633.3333333333333, 857.5757575757574, 919.6969696969696]\n",
      "[481.72679901123047, 384.32570457458496, 800.9422874450682, 636.2129402160645] [483.33333333333326, 665.1515151515151, 875.7575757575756, 954.5454545454545]\n",
      "[430.7119560241699, 314.29670333862305, 758.4966945648193, 549.3626689910889] [438.0, 588.0, 774.0, 894.0]\n",
      "[468.0706214904785, 728.6234951019287, 789.2531776428222, 929.1256999969482] [427.27272727272725, 703.030303030303, 840.9090909090909, 1022.7272727272727]\n",
      "[443.91563415527344, 485.28581142425537, 643.5637807846068, 659.3663263320923] [490.9090909090908, 643.9393939393939, 889.3939393939394, 939.3939393939393]\n",
      "[120.07756233215332, 551.6334915161133, 373.0124044418335, 921.1201858520508] [421.21212121212113, 601.5151515151514, 815.1515151515151, 898.4848484848485]\n",
      "[530.5182838439941, 697.1885204315186, 780.5683135986328, 869.0256786346436] [413.63636363636357, 659.090909090909, 836.3636363636363, 953.0303030303029]\n",
      "[401.824779510498, 374.952392578125, 831.3268661499022, 711.1569499969482] [434.0, 686.0, 888.0, 1066.0]\n",
      "[202.04166412353516, 704.4181251525879, 663.6713790893555, 1045.4725456237793] [306.0, 744.0000000000001, 766.0, 1132.0]\n",
      "[346.57198190689087, 375.18877029418945, 745.4848480224609, 707.2386932373047] [346.0, 686.0, 808.0, 1110.0]\n",
      "[325.57060718536377, 619.4958686828613, 700.0458669662476, 964.4957542419434] [294.0, 766.0, 756.0, 1164.0]\n",
      "[346.03118419647217, 657.6345634460449, 751.8569183349609, 1036.2297821044922] [328.0, 686.0, 776.0, 1062.0]\n",
      "[347.0175075531006, 349.18267250061035, 728.2495307922363, 682.6255416870117] [282.0, 652.0, 747.9999999999999, 1038.0]\n",
      "[451.4210987091064, 668.9884185791016, 717.6972055435181, 918.0886459350586] [474.0, 698.0, 802.0, 1002.0]\n",
      "[401.0627746582031, 712.8910732269287, 805.8685398101807, 1007.2190952301025] [373.99999999999994, 714.0, 848.0, 1044.0]\n",
      "[366.90962791442865, 629.8119449615479, 722.9397010803222, 949.2519664764404] [340.0, 756.0, 776.0, 1074.0]\n",
      "[450.10866165161127, 337.9415988922119, 793.0953025817871, 671.8389415740967] [452.0, 666.0, 860.0, 968.0000000000001]\n",
      "[356.1188220977783, 683.4034252166748, 726.8475723266602, 989.5849227905273] [332.0, 720.0, 778.0, 1048.0]\n",
      "[444.7591781616211, 282.3118543624878, 803.9908218383789, 617.0900774002075] [440.0, 570.0, 868.0, 950.0]\n",
      "[388.3568286895752, 495.40597915649414, 736.8380069732666, 855.3680419921875] [364.0, 716.0, 832.0, 1064.0]\n",
      "[476.5013408660888, 364.14592266082764, 711.2186193466187, 642.4088430404663] [506.0, 650.0, 964.0, 1040.0]\n",
      "[421.8884754180908, 405.60948371887207, 681.3693237304688, 711.1790943145752] [430.0, 704.0, 854.0, 1078.0]\n",
      "[536.8513011932373, 627.7039432525635, 806.8561935424805, 927.6173973083496] [532.0, 602.0, 1006.0, 988.0]\n",
      "[478.1414794921875, 767.5004196166992, 750.1488018035889, 995.0049591064453] [476.0, 722.0, 938.0, 1082.0]\n",
      "[476.24058723449707, 342.8264808654785, 804.6291446685791, 594.4820594787598] [470.0, 638.0, 818.0, 904.0]\n",
      "[408.2879161834717, 631.6656303405762, 758.1986904144287, 1031.6076278686523] [410.0, 693.3333333333333, 811.6666666666666, 1120.0]\n",
      "[349.3829154968261, 379.5277690887451, 670.8484554290771, 809.36279296875] [258.3333333333333, 781.6666666666666, 690.0, 1211.6666666666667]\n",
      "[329.5520782470703, 721.1691856384277, 732.7013969421387, 1157.5827026367188] [310.0, 743.3333333333334, 731.6666666666666, 1208.3333333333333]\n",
      "[274.2726516723633, 705.3380584716797, 667.5490379333495, 1089.64994430542] [245.0, 723.3333333333333, 670.0, 1183.3333333333335]\n",
      "[391.8782043457031, 255.28488636016846, 757.7267932891846, 704.6247625350952] [400.0, 676.6666666666666, 806.6666666666666, 1131.6666666666667]\n",
      "[329.0525007247924, 697.1226024627686, 692.4915647506714, 1105.0344944000244] [313.33333333333337, 715.0, 711.6666666666667, 1151.6666666666665]\n",
      "[358.2610273361206, 720.6794357299805, 733.6511993408203, 1131.3288116455078] [370.0, 743.3333333333334, 786.6666666666666, 1183.3333333333335]\n",
      "[313.57353687286377, 759.2414474487305, 688.3312654495239, 1166.689510345459] [301.6666666666667, 801.6666666666666, 708.3333333333334, 1230.0]\n",
      "[295.0142383575439, 729.2187309265137, 643.2027339935303, 1147.1621704101562] [276.6666666666667, 791.6666666666666, 700.0, 1215.0]\n",
      "[309.6364188194275, 714.1192245483398, 683.5317420959473, 1130.456428527832] [286.6666666666667, 848.3333333333333, 713.3333333333334, 1278.3333333333335]\n",
      "[401.7538833618164, 316.29509925842285, 725.3975486755371, 582.5838661193848] [400.0, 628.0, 738.0, 900.0]\n",
      "[370.87603569030756, 824.1309070587158, 608.0337381362914, 1141.1716175079346] [361.66666666666663, 856.6666666666667, 758.3333333333334, 1286.6666666666665]\n",
      "[369.1101121902466, 732.4648475646973, 691.7672395706177, 1076.33451461792] [370.0, 783.3333333333334, 766.6666666666667, 1181.6666666666667]\n",
      "[371.0404872894287, 863.6017799377441, 591.6180610656738, 1101.8509483337402] [346.66666666666663, 826.6666666666666, 756.6666666666666, 1253.3333333333333]\n",
      "[396.6149425506591, 783.0297660827637, 602.6524543762207, 1029.3590354919434] [405.0, 739.9999999999999, 793.3333333333334, 1176.6666666666667]\n",
      "[364.5032787322998, 849.0501308441162, 604.7501564025879, 1103.9537143707275] [323.3333333333333, 810.0, 723.3333333333333, 1236.6666666666667]\n",
      "[367.9695510864258, 366.09174728393555, 616.0313558578491, 715.339994430542] [376.6666666666667, 811.6666666666667, 796.6666666666666, 1258.3333333333333]\n",
      "[475.0888252258301, 357.14372634887695, 806.6465950012207, 617.8085231781006] [510.0, 692.0, 834.0, 974.0]\n",
      "[417.5590896606445, 365.3833866119385, 752.0419692993163, 638.1985473632812] [478.0, 726.0, 792.0, 998.0]\n",
      "[127.01903343200684, 1013.1368637084961, 287.5219488143921, 1201.9511604309082] [557.5757575757575, 687.8787878787879, 956.0606060606059, 978.7878787878786]\n",
      "[425.4210948944091, 400.5302381515503, 731.5514373779297, 630.8656454086304] [413.63636363636357, 671.2121212121211, 796.9696969696969, 942.4242424242424]\n",
      "[456.6754817962646, 657.1264457702637, 678.6985301971436, 889.8036575317383] [472.0, 652.0, 816.0, 912.0]\n",
      "[535.4515743255615, 461.14760398864746, 840.0724124908447, 714.2564678192139] [539.3939393939394, 703.030303030303, 939.3939393939393, 998.4848484848484]\n",
      "[421.7755222320556, 413.2419776916504, 718.0892372131348, 670.8975505828857] [424.0, 680.0, 774.0, 958.0]\n",
      "[498.7270259857177, 408.05437088012695, 834.686450958252, 662.8360748291016] [528.0, 688.0, 870.0, 963.9999999999999]\n",
      "[307.8707528114318, 501.9803524017334, 683.2242965698242, 896.7194652557373] [232.85714285714286, 990.0000000000001, 655.7142857142857, 1341.4285714285716]\n",
      "[375.5782699584961, 876.4583587646484, 759.880027770996, 1248.8840675354004] [360.0, 964.2857142857143, 780.0, 1317.1428571428573]\n",
      "[395.1786518096923, 940.0249099731445, 776.8064403533936, 1289.9209213256836] [377.1428571428571, 1034.2857142857144, 795.7142857142857, 1382.8571428571431]\n",
      "[375.40489196777344, 879.8497009277344, 771.9972610473633, 1267.5968742370605] [365.71428571428567, 1000.0000000000001, 778.5714285714286, 1368.5714285714287]\n",
      "[359.55621242523193, 928.5468578338623, 754.1544342041014, 1287.695074081421] [342.85714285714283, 1040.0000000000002, 758.5714285714286, 1398.5714285714287]\n",
      "[368.00851821899414, 809.0061664581299, 730.5603504180908, 1241.5940380096436] [352.8571428571429, 1020.0, 767.1428571428572, 1345.7142857142858]\n",
      "[372.430944442749, 931.4691352844238, 660.9348392486571, 1291.618995666504] [357.14285714285717, 1084.2857142857144, 771.4285714285714, 1407.1428571428573]\n",
      "[368.4218788146972, 898.4316158294678, 630.9998846054077, 1283.9305400848389] [350.0, 1060.0, 764.2857142857143, 1391.4285714285716]\n",
      "[419.6807384490967, 928.7894153594971, 746.2711429595947, 1283.1772899627686] [421.42857142857144, 1067.142857142857, 832.8571428571429, 1388.5714285714287]\n",
      "[422.9201602935791, 912.0315742492676, 694.2779159545898, 1262.7434921264648] [405.71428571428567, 1041.4285714285716, 807.1428571428571, 1324.2857142857144]\n",
      "[430.5131721496582, 767.7698421478271, 718.5728073120117, 1113.2605075836182] [398.5714285714286, 1037.1428571428573, 798.5714285714286, 1358.5714285714287]\n",
      "[363.26688766479487, 925.7217407226562, 729.6751785278319, 1221.049518585205] [354.2857142857143, 997.1428571428572, 760.0, 1340.0000000000002]\n",
      "[415.4751205444336, 958.5269165039062, 621.8690872192383, 1256.5638542175293] [398.5714285714286, 1017.1428571428572, 802.8571428571429, 1358.5714285714287]\n",
      "[453.49279403686523, 951.4522361755371, 809.5816612243651, 1185.9344673156738] [432.8571428571429, 1008.5714285714287, 837.1428571428571, 1340.0000000000002]\n",
      "[427.69466400146484, 966.9772052764893, 712.3949289321899, 1275.6983470916748] [398.5714285714286, 1040.0000000000002, 795.7142857142857, 1371.4285714285716]\n",
      "[322.57344245910645, 530.9307861328125, 672.6745891571045, 819.054708480835] [294.2857142857143, 855.7142857142859, 631.4285714285714, 1152.857142857143]\n",
      "[314.86906528472895, 717.2503280639648, 667.5536727905272, 1005.0536727905273] [334.2857142857143, 802.8571428571429, 664.2857142857143, 1068.5714285714287]\n",
      "[290.36058425903315, 756.2521362304688, 652.9322433471679, 1035.5695724487305] [290.00000000000006, 831.4285714285716, 610.0, 1097.1428571428573]\n",
      "[326.86810970306396, 547.1926975250244, 671.1804914474487, 821.7365741729736] [317.14285714285717, 858.5714285714287, 641.4285714285714, 1142.857142857143]\n",
      "[283.7360858917236, 732.4216747283936, 632.2992324829102, 1058.5221576690674] [274.2857142857143, 837.1428571428572, 600.0, 1122.8571428571431]\n",
      "[294.0585994720459, 517.2115230560303, 639.0483570098877, 798.660306930542] [258.57142857142856, 830.0000000000001, 591.4285714285714, 1105.7142857142858]\n",
      "[274.8417949676513, 583.5679149627686, 609.7086811065674, 912.006254196167] [262.85714285714283, 838.5714285714287, 598.5714285714286, 1125.7142857142858]\n",
      "[278.94042491912836, 737.5831031799316, 566.1878013610839, 1041.068058013916] [261.42857142857144, 842.8571428571429, 594.2857142857142, 1100.0]\n",
      "[318.0456590652466, 779.018383026123, 636.2251710891724, 1088.39750289917] [322.8571428571429, 861.4285714285716, 652.8571428571429, 1137.1428571428573]\n",
      "[334.8029851913452, 704.4907379150391, 642.307391166687, 1087.445297241211] [330.0, 874.2857142857143, 658.5714285714286, 1158.5714285714287]\n",
      "[337.07586765289307, 533.6546230316162, 682.6129245758057, 818.5526847839355] [305.7142857142857, 875.7142857142858, 640.0, 1160.0000000000002]\n",
      "[327.7456212043762, 549.7865867614746, 664.0288639068602, 824.1193199157715] [305.7142857142857, 854.2857142857144, 637.1428571428572, 1147.1428571428573]\n",
      "[329.5064163208008, 733.7290477752686, 556.5778541564941, 1034.4567775726318] [300.0, 805.7142857142858, 637.1428571428572, 1085.7142857142858]\n",
      "[308.815426826477, 502.9911804199219, 605.6294059753417, 773.3290100097656] [265.7142857142857, 812.857142857143, 608.5714285714286, 1072.8571428571431]\n",
      "[297.44603633880615, 651.2683296203613, 609.193696975708, 982.0230674743652] [267.14285714285717, 828.5714285714287, 607.1428571428572, 1090.0000000000002]\n",
      "[364.01344299316406, 745.2505302429199, 782.0651149749756, 1127.4090957641602] [370.0, 821.4285714285716, 797.1428571428572, 1180.0000000000002]\n",
      "[353.9187240600586, 762.8503704071045, 778.989372253418, 1123.3384037017822] [351.42857142857144, 847.1428571428572, 781.4285714285713, 1192.857142857143]\n",
      "[418.4250354766845, 708.7704277038574, 794.285945892334, 1103.3946990966797] [400.0, 894.2857142857144, 822.8571428571428, 1251.4285714285716]\n",
      "[357.0257091522217, 755.5718421936035, 772.7132606506348, 1127.2659301757812] [361.42857142857144, 820.0000000000001, 792.8571428571428, 1208.5714285714287]\n",
      "[357.16243743896484, 802.1079540252686, 775.817928314209, 1156.4647579193115] [375.7142857142857, 870.0000000000001, 792.8571428571428, 1227.1428571428573]\n",
      "[328.50966453552246, 778.0771636962891, 750.2416706085205, 1134.6331214904785] [325.7142857142857, 828.5714285714287, 742.8571428571428, 1190.0]\n",
      "[351.7907238006591, 834.4950485229492, 775.7099533081055, 1162.4390029907227] [375.7142857142857, 868.5714285714287, 800.0, 1235.7142857142858]\n",
      "[385.46218872070307, 517.2356414794922, 823.6750602722168, 831.6153430938721] [390.0, 905.7142857142859, 811.4285714285713, 1264.2857142857144]\n",
      "[352.4003791809082, 845.5304718017578, 789.8565673828125, 1163.3149909973145] [388.57142857142856, 881.4285714285714, 801.4285714285714, 1231.4285714285716]\n",
      "[368.5626411437988, 817.5125026702881, 629.5832920074463, 1168.03147315979] [365.71428571428567, 875.7142857142858, 778.5714285714286, 1247.1428571428573]\n",
      "[383.89440536499023, 513.2711219787598, 681.5720987319946, 783.087100982666] [355.7142857142857, 882.8571428571429, 777.1428571428571, 1235.7142857142858]\n",
      "[415.28637886047363, 531.8924331665039, 770.5709266662598, 834.1726684570312] [394.2857142857143, 908.5714285714287, 804.2857142857142, 1272.857142857143]\n",
      "[411.1747455596924, 533.9870452880859, 826.7038536071776, 819.1445732116699] [392.8571428571429, 867.1428571428572, 805.7142857142858, 1220.0000000000002]\n",
      "[368.4364700317383, 556.7841053009033, 680.7650756835936, 854.7511768341064] [355.7142857142857, 898.5714285714288, 761.4285714285714, 1268.5714285714287]\n",
      "[419.01692390441895, 639.0294742584229, 743.9855575561522, 898.6316013336182] [388.57142857142856, 901.4285714285716, 792.8571428571428, 1230.0]\n",
      "[307.8707528114318, 501.9803524017334, 683.2242965698242, 896.7194652557373] [232.85714285714286, 990.0000000000001, 655.7142857142857, 1341.4285714285716]\n",
      "[375.5782699584961, 876.4583587646484, 759.880027770996, 1248.8840675354004] [360.0, 964.2857142857143, 780.0, 1317.1428571428573]\n",
      "[395.1786518096923, 940.0249099731445, 776.8064403533936, 1289.9209213256836] [377.1428571428571, 1034.2857142857144, 795.7142857142857, 1382.8571428571431]\n",
      "[375.40489196777344, 879.8497009277344, 771.9972610473633, 1267.5968742370605] [365.71428571428567, 1000.0000000000001, 778.5714285714286, 1368.5714285714287]\n",
      "[359.55621242523193, 928.5468578338623, 754.1544342041014, 1287.695074081421] [342.85714285714283, 1040.0000000000002, 758.5714285714286, 1398.5714285714287]\n",
      "[368.00851821899414, 809.0061664581299, 730.5603504180908, 1241.5940380096436] [352.8571428571429, 1020.0, 767.1428571428572, 1345.7142857142858]\n",
      "[372.430944442749, 931.4691352844238, 660.9348392486571, 1291.618995666504] [357.14285714285717, 1084.2857142857144, 771.4285714285714, 1407.1428571428573]\n",
      "[368.4218788146972, 898.4316158294678, 630.9998846054077, 1283.9305400848389] [350.0, 1060.0, 764.2857142857143, 1391.4285714285716]\n",
      "[419.6807384490967, 928.7894153594971, 746.2711429595947, 1283.1772899627686] [421.42857142857144, 1067.142857142857, 832.8571428571429, 1388.5714285714287]\n",
      "[422.9201602935791, 912.0315742492676, 694.2779159545898, 1262.7434921264648] [405.71428571428567, 1041.4285714285716, 807.1428571428571, 1324.2857142857144]\n",
      "[430.5131721496582, 767.7698421478271, 718.5728073120117, 1113.2605075836182] [398.5714285714286, 1037.1428571428573, 798.5714285714286, 1358.5714285714287]\n",
      "[363.26688766479487, 925.7217407226562, 729.6751785278319, 1221.049518585205] [354.2857142857143, 997.1428571428572, 760.0, 1340.0000000000002]\n",
      "[415.4751205444336, 958.5269165039062, 621.8690872192383, 1256.5638542175293] [398.5714285714286, 1017.1428571428572, 802.8571428571429, 1358.5714285714287]\n",
      "[453.49279403686523, 951.4522361755371, 809.5816612243651, 1185.9344673156738] [432.8571428571429, 1008.5714285714287, 837.1428571428571, 1340.0000000000002]\n",
      "[427.69466400146484, 966.9772052764893, 712.3949289321899, 1275.6983470916748] [398.5714285714286, 1040.0000000000002, 795.7142857142857, 1371.4285714285716]\n",
      "[322.57344245910645, 530.9307861328125, 672.6745891571045, 819.054708480835] [294.2857142857143, 855.7142857142859, 631.4285714285714, 1152.857142857143]\n",
      "[314.86906528472895, 717.2503280639648, 667.5536727905272, 1005.0536727905273] [334.2857142857143, 802.8571428571429, 664.2857142857143, 1068.5714285714287]\n",
      "[290.36058425903315, 756.2521362304688, 652.9322433471679, 1035.5695724487305] [290.00000000000006, 831.4285714285716, 610.0, 1097.1428571428573]\n",
      "[326.86810970306396, 547.1926975250244, 671.1804914474487, 821.7365741729736] [317.14285714285717, 858.5714285714287, 641.4285714285714, 1142.857142857143]\n",
      "[283.7360858917236, 732.4216747283936, 632.2992324829102, 1058.5221576690674] [274.2857142857143, 837.1428571428572, 600.0, 1122.8571428571431]\n",
      "[294.0585994720459, 517.2115230560303, 639.0483570098877, 798.660306930542] [258.57142857142856, 830.0000000000001, 591.4285714285714, 1105.7142857142858]\n",
      "[274.8417949676513, 583.5679149627686, 609.7086811065674, 912.006254196167] [262.85714285714283, 838.5714285714287, 598.5714285714286, 1125.7142857142858]\n",
      "[278.94042491912836, 737.5831031799316, 566.1878013610839, 1041.068058013916] [261.42857142857144, 842.8571428571429, 594.2857142857142, 1100.0]\n",
      "[318.0456590652466, 779.018383026123, 636.2251710891724, 1088.39750289917] [322.8571428571429, 861.4285714285716, 652.8571428571429, 1137.1428571428573]\n",
      "[334.8029851913452, 704.4907379150391, 642.307391166687, 1087.445297241211] [330.0, 874.2857142857143, 658.5714285714286, 1158.5714285714287]\n",
      "[337.07586765289307, 533.6546230316162, 682.6129245758057, 818.5526847839355] [305.7142857142857, 875.7142857142858, 640.0, 1160.0000000000002]\n",
      "[327.7456212043762, 549.7865867614746, 664.0288639068602, 824.1193199157715] [305.7142857142857, 854.2857142857144, 637.1428571428572, 1147.1428571428573]\n",
      "[329.5064163208008, 733.7290477752686, 556.5778541564941, 1034.4567775726318] [300.0, 805.7142857142858, 637.1428571428572, 1085.7142857142858]\n",
      "[308.815426826477, 502.9911804199219, 605.6294059753417, 773.3290100097656] [265.7142857142857, 812.857142857143, 608.5714285714286, 1072.8571428571431]\n",
      "[297.44603633880615, 651.2683296203613, 609.193696975708, 982.0230674743652] [267.14285714285717, 828.5714285714287, 607.1428571428572, 1090.0000000000002]\n",
      "[364.01344299316406, 745.2505302429199, 782.0651149749756, 1127.4090957641602] [370.0, 821.4285714285716, 797.1428571428572, 1180.0000000000002]\n",
      "[353.9187240600586, 762.8503704071045, 778.989372253418, 1123.3384037017822] [351.42857142857144, 847.1428571428572, 781.4285714285713, 1192.857142857143]\n",
      "[418.4250354766845, 708.7704277038574, 794.285945892334, 1103.3946990966797] [400.0, 894.2857142857144, 822.8571428571428, 1251.4285714285716]\n",
      "[357.0257091522217, 755.5718421936035, 772.7132606506348, 1127.2659301757812] [361.42857142857144, 820.0000000000001, 792.8571428571428, 1208.5714285714287]\n",
      "[357.16243743896484, 802.1079540252686, 775.817928314209, 1156.4647579193115] [375.7142857142857, 870.0000000000001, 792.8571428571428, 1227.1428571428573]\n",
      "[328.50966453552246, 778.0771636962891, 750.2416706085205, 1134.6331214904785] [325.7142857142857, 828.5714285714287, 742.8571428571428, 1190.0]\n",
      "[351.7907238006591, 834.4950485229492, 775.7099533081055, 1162.4390029907227] [375.7142857142857, 868.5714285714287, 800.0, 1235.7142857142858]\n",
      "[385.46218872070307, 517.2356414794922, 823.6750602722168, 831.6153430938721] [390.0, 905.7142857142859, 811.4285714285713, 1264.2857142857144]\n",
      "[352.4003791809082, 845.5304718017578, 789.8565673828125, 1163.3149909973145] [388.57142857142856, 881.4285714285714, 801.4285714285714, 1231.4285714285716]\n",
      "[368.5626411437988, 817.5125026702881, 629.5832920074463, 1168.03147315979] [365.71428571428567, 875.7142857142858, 778.5714285714286, 1247.1428571428573]\n",
      "[383.89440536499023, 513.2711219787598, 681.5720987319946, 783.087100982666] [355.7142857142857, 882.8571428571429, 777.1428571428571, 1235.7142857142858]\n",
      "[415.28637886047363, 531.8924331665039, 770.5709266662598, 834.1726684570312] [394.2857142857143, 908.5714285714287, 804.2857142857142, 1272.857142857143]\n",
      "[411.1747455596924, 533.9870452880859, 826.7038536071776, 819.1445732116699] [392.8571428571429, 867.1428571428572, 805.7142857142858, 1220.0000000000002]\n",
      "[368.4364700317383, 556.7841053009033, 680.7650756835936, 854.7511768341064] [355.7142857142857, 898.5714285714288, 761.4285714285714, 1268.5714285714287]\n",
      "[419.01692390441895, 639.0294742584229, 743.9855575561522, 898.6316013336182] [388.57142857142856, 901.4285714285716, 792.8571428571428, 1230.0]\n"
     ]
    }
   ],
   "source": [
    "report_target_part1 = val_dataset_target_part1.perform_evaluation(model, model_type=\"classic\")\n",
    "report_target_part2 = val_dataset_target_part2.perform_evaluation(model, model_type=\"classic\")\n",
    "report_target = merge_evaluation_reports(report_target_part1, report_target_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.616\n",
      "  Min:  0.000\n",
      "  Max:  1.000\n",
      "  Count: 170\n",
      "IOU:\n",
      "  Mean: 0.386\n",
      "  Min:  0.000\n",
      "  Max:  0.813\n",
      "  Count: 170\n"
     ]
    }
   ],
   "source": [
    "print(report_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_eval_framework import merge_evaluation_reports\n",
    "report_target = merge_evaluation_reports(report_target_part1, report_target_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationReport:\n",
      "PCK:\n",
      "  Mean: 0.617\n",
      "  Min:  0.000\n",
      "  Max:  1.000\n",
      "  Count: 170\n",
      "IOU:\n",
      "  Mean: 0.372\n",
      "  Min:  0.000\n",
      "  Max:  0.813\n",
      "  Count: 170\n"
     ]
    }
   ],
   "source": [
    "print(report_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
